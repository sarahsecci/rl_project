# @package _global_
env:
  name: "MiniGrid-DoorKey-6x6-v0" # Environment name
  wrapper: "FlatObsWrapper"       # FlatObsWrapper or RGBImgObsWrapper

seed: 0 # Random seed for reproducibility

agent:
  type:                   "rnd"       # Possible values: "dqn", "rnd"
  buffer_capacity:        72197       # Max replay buffer size
  batch_size:             64          # Minibatch size
  gamma:                  0.950       # Discount factor
  epsilon_start:          1.0         # Initial value of epsilon
  epsilon_final:          0.0669      # Final value of epsilon
  epsilon_decay:          11514       # Decay steps for epsilon
  dqn_hidden_size:        64          # Hidden size for DQN networks
  dqn_lr:                 0.000185    # Maps to DQNAgentâ€™s lr
  dqn_target_update_freq: 302         # Update target network every this many steps
  rnd_type:               "on_sample" # Possible values: "naive", "on_sample"
  rnd_hidden_size:        32          # Hidden size for RND networks
  rnd_output_size:        16          # Output size for RND networks
  rnd_lr:                 0.000975    # Learning rate for RND networks
  rnd_update_freq:        705         # Update RND networks every this many steps   
  rnd_reward_weight:      0.141       # Weight for RND reward in total reward
  
train:
  num_frames:             60000  # Total env steps
  vmap_save_every_n:      5000   # Save visitation map every nth step to reduce file size.
  minibatch_window:       250     # Rolling window size for averaging minibatch values.
  minibatch_save_every_n: 50      # Save minibatch values every nth step to reduce file size.
  eval_interval:          10      # Print average episode reward every eval_interval steps in terminal.
  saved_decimals:         5       # number of decimals saved in the csv