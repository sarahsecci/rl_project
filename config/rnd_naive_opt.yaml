# @package _global_
env:
  name: "MiniGrid-DoorKey-6x6-v0" # Environment name
  wrapper: "FlatObsWrapper"       # FlatObsWrapper or RGBImgObsWrapper

seed: 0 # Random seed for reproducibility

agent:
  type:                   "rnd"     # Possebile values: "dqn", "rnd"
  buffer_capacity:        54567     # Max replay buffer size
  batch_size:             256       # Minibatch size
  gamma:                  0.977     # Discount factor
  epsilon_start:          1.0       # Initial value of epsilon
  epsilon_final:          0.0259    # Final value of epsilon
  epsilon_decay:          10544     # Decay steps for epsilon
  dqn_hidden_size:        32        # Hidden size for DQN networks
  dqn_lr:                 0.000108  # Maps to DQNAgentâ€™s lr
  dqn_target_update_freq: 270       # Update target network every this many steps
  rnd_type:               "naive"   # Possible values: "naive", "on_sample"
  rnd_hidden_size:        32        # Hidden size for RND networks
  rnd_output_size:        16        # Output size for RND networks
  rnd_lr:                 0.000136  # Learning rate for RND networks
  rnd_update_freq:        935       # Update RND networks every this many steps   
  rnd_reward_weight:      0.0241    # Weight for RND reward in total reward
  
train:
  num_frames:             50000 # Total env steps
  vmap_save_every_n:      5000  # Save visitation map every nth step to reduce file size.
  minibatch_window:       250   # Rolling window size for averaging minibatch values.
  minibatch_save_every_n: 50    # Save minibatch values every nth step to reduce file size.
  eval_interval:          10    # Print average episode reward every eval_interval steps in terminal.
  saved_decimals:         5     # number of decimals saved in the csv