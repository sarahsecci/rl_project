# @package _global_
env:
  name: "MiniGrid-DoorKey-6x6-v0" # Environment name
  wrapper: "FlatObsWrapper" # FlatObsWrapper or RGBImgObsWrapper

seed: 0   # Random seed for reproducibility

agent:
  type:                   "rnd"   # Possebile values: "dqn", "rnd"
  buffer_capacity:        25000   # Max replay buffer size
  batch_size:             32      # Minibatch size
  gamma:                  0.99    # Discount factor
  epsilon_start:          1.0     # Initial value of epsilon
  epsilon_final:          0.05    # Final value of epsilon
  epsilon_decay:          200000    # Decay steps for epsilon
  dqn_hidden_size:        64      # Hidden size for DQN networks
  dqn_lr:                 2e-5   # Maps to DQNAgentâ€™s lr
  dqn_target_update_freq: 1000    # Update target network every this many steps
  rnd_type:               "naive" # Possible values: "naive", "on_sample"
  rnd_hidden_size:        128      # Hidden size for RND networks
  rnd_output_size:        64      # Output size for RND networks
  rnd_lr:                 0.01   # Learning rate for RND networks
  rnd_update_freq:        700    # Update RND networks every this many steps   
  rnd_reward_weight:      0.5     # Weight for RND reward in total reward
  
train:
  num_frames:             250000  # Total env steps
  vmap_save_every_n:      5000   # Save visitation map every nth step to reduce file size.
  minibatch_window:       100     # Rolling window size for averaging minibatch values.
  minibatch_save_every_n: 20      # Save minibatch values every nth step to reduce file size.
  eval_interval:          10      # Print average episode reward every eval_interval steps in terminal.
  saved_decimals:         5       # number of decimals saved in the csv