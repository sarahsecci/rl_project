# @package _global_

# Defaults & plugin override
defaults:
  - sweep_base
  - _self_
  - override hydra/sweeper: HyperRS

# Global flags
seed: 0
n_trials: 12
num_frames: 200000

# Hydra output & sweeper settings
hydra:
  run:
    dir: ../results/sweeps/${env.name}_${agent.type}_${agent.rnd_type}_seed_${seed}
  sweep:
    dir: ../results/sweeps/${env.name}_${agent.type}_${agent.rnd_type}_seed_${seed}
  sweeper:
    n_trials: ${n_trials}
    sweeper_kwargs:
      max_parallelization: 0.5
      max_budget: 60
    search_space: ${search_space}

# Environment configuration
env:
  name: "MiniGrid-DoorKey-6x6-v0"
  wrapper: "FlatObsWrapper"

# Agent configuration with best DQN hyperparameters
agent:
  type: "rnd"
  buffer_capacity: 20000
  batch_size: 32
  gamma: 0.99
  epsilon_start: 1.0
  epsilon_final: 0.1
  epsilon_decay: 50000
  dqn_hidden_size: 64
  dqn_lr: 0.001
  dqn_target_update_freq: 500
  
  # RND-specific parameters
  rnd_type: "on_sample"
  rnd_hidden_size: 64
  rnd_output_size: 64
  rnd_lr: 0.001
  rnd_update_freq: 1000
  rnd_reward_weight: 0.01

# Training configuration
train:
  num_frames: ${num_frames}
  eval_interval: 100
  saved_decimals: 5

# For sweep identification
sweep:
  run_id: null
  phase: "rnd_on_sample"

# Search space definition
search_space:
  seed: ${seed}
  hyperparameters:
    agent.buffer_capacity:
      type: uniform_int
      lower: 10000
      upper: 100000
      log: false
    agent.batch_size:
      type: categorical
      choices: [32, 64]
    agent.epsilon_final:
      type: uniform_float
      lower: 0.01
      upper: 0.4
      log: false
    agent.epsilon_decay:
      type: uniform_int
      lower: 50000
      upper: 250000
      log: false
    agent.dqn_target_update_freq:
      type: uniform_int
      lower: 100
      upper: 1000
      log: false
    agent.dqn_lr:
      type: uniform_float
      lower: 1e-5
      upper: 1e-2
      log: true
    agent.rnd_update_freq:
      type: uniform_int
      lower: 100
      upper: 1000
      log: false
    agent.rnd_lr:
      type: uniform_float
      lower: 1e-5
      upper: 1e-2
      log: true
    agent.rnd_reward_weight:
      type: uniform_float
      lower: 5e-3
      upper: 5e-1
      log: false
    
    